{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE4DUKx-1Z8z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E_qkXiJddOVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/My Drive/course work/dataset_part1.zip\""
      ],
      "metadata": {
        "id": "YAEogd0a1cRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/My Drive/course work/dataset_part2.zip\""
      ],
      "metadata": {
        "id": "dXq2zuA31iX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir='dataset_part1/'\n",
        "validation_dir='dataset_part2/'"
      ],
      "metadata": {
        "id": "VjNWfcDw1kry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape,AveragePooling2D, SeparableConv2D,Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install mtcnn\n",
        "\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "22YsZT641q_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Validation set**"
      ],
      "metadata": {
        "id": "1q3_OvmF1wWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zone1_dir_valid=os.path.join(validation_dir, 'zone1')\n",
        "fnames_valid = [os.path.join(zone1_dir_valid, fname) for fname in os.listdir(zone1_dir_valid)]\n",
        "zone2_dir_valid=os.path.join(validation_dir, 'zone2')\n",
        "fnames_valid.extend([os.path.join(zone2_dir_valid, fname) for fname in os.listdir(zone2_dir_valid)])\n",
        "zone3_dir_valid=os.path.join(validation_dir, 'zone3')\n",
        "fnames_valid.extend([os.path.join(zone3_dir_valid, fname) for fname in os.listdir(zone3_dir_valid)])\n",
        "zone4_dir_valid=os.path.join(validation_dir, 'zone4')\n",
        "fnames_valid.extend([os.path.join(zone4_dir_valid, fname) for fname in os.listdir(zone4_dir_valid)])\n",
        "zone5_dir_valid=os.path.join(validation_dir, 'zone5')\n",
        "fnames_valid.extend([os.path.join(zone5_dir_valid, fname) for fname in os.listdir(zone5_dir_valid)])\n",
        "zone6_dir_valid=os.path.join(validation_dir, 'zone6')\n",
        "fnames_valid.extend([os.path.join(zone6_dir_valid, fname) for fname in os.listdir(zone6_dir_valid)])\n",
        "zone7_dir_valid=os.path.join(validation_dir, 'zone7')\n",
        "fnames_valid.extend([os.path.join(zone7_dir_valid, fname) for fname in os.listdir(zone7_dir_valid)])"
      ],
      "metadata": {
        "id": "o4N7vZDb1wDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "k = 0\n",
        "f = 0\n",
        "for img_path in fnames_valid:\n",
        "  img = cv2.imread(img_path)\n",
        "  output = detector.detect_faces(img)\n",
        "  print(output)                                                                 #[{},{}...{}]\n",
        "  for i in output:\n",
        "    x,y,width,height = i['box']\n",
        "    left_eyeX,left_eyeY = i['keypoints']['left_eye']\n",
        "    right_eyeX,right_eyeY = i['keypoints']['right_eye']\n",
        "    noseX,noseY = i['keypoints']['nose']\n",
        "    mouth_leftX,mouth_leftY = i['keypoints']['mouth_left']\n",
        "    mouth_rightX,mouth_rightY = i['keypoints']['mouth_right']\n",
        "\n",
        "    cv2.circle(img,center=(left_eyeX,left_eyeY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(right_eyeX,right_eyeY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(noseX,noseY),color=(0,0,0),thickness=0,radius=2)\n",
        "    cv2.circle(img,center=(mouth_leftX,mouth_leftY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(mouth_rightX,mouth_rightY),color=(0,0,0),thickness=0,radius=0)\n",
        "\n",
        "    cv2.rectangle(img,pt1=(x,y),pt2=(x+width,y+height),color=(0,0,0),thickness=0)\n",
        "\n",
        "  if len(output) == 0:\n",
        "    img1 = img[150:150+250, 180:180+200]\n",
        "  else:\n",
        "    img1 = img[y:y+height, x:x+width]\n",
        "  cv2.imwrite(img_path, img1)\n",
        "  cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "0l9YM1a_14vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train set**"
      ],
      "metadata": {
        "id": "AfNIS6R92cG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zone1_train_dir=os.path.join(train_dir, 'zone1')\n",
        "fnames_train = [os.path.join(zone1_train_dir, fname) for fname in os.listdir(zone1_train_dir)]\n",
        "zone2_train_dir=os.path.join(train_dir, 'zone2')\n",
        "fnames_train.extend([os.path.join(zone2_train_dir, fname) for fname in os.listdir(zone2_train_dir)])\n",
        "zone3_train_dir=os.path.join(train_dir, 'zone3')\n",
        "fnames_train.extend([os.path.join(zone3_train_dir, fname) for fname in os.listdir(zone3_train_dir)])\n",
        "zone4_train_dir=os.path.join(train_dir, 'zone4')\n",
        "fnames_train.extend([os.path.join(zone4_train_dir, fname) for fname in os.listdir(zone4_train_dir)])\n",
        "zone5_train_dir=os.path.join(train_dir, 'zone5')\n",
        "fnames_train.extend([os.path.join(zone5_train_dir, fname) for fname in os.listdir(zone5_train_dir)])\n",
        "zone6_train_dir=os.path.join(train_dir, 'zone6')\n",
        "fnames_train.extend([os.path.join(zone6_train_dir, fname) for fname in os.listdir(zone6_train_dir)])\n",
        "zone7_train_dir=os.path.join(train_dir, 'zone7')\n",
        "fnames_train.extend([os.path.join(zone7_train_dir, fname) for fname in os.listdir(zone7_train_dir)])"
      ],
      "metadata": {
        "id": "jktkcTqW2Rdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "\n",
        "for img_path in fnames_train:\n",
        "  img = cv2.imread(img_path)\n",
        "  output = detector.detect_faces(img)\n",
        "  print(output)                                                                 #[{},{}...{}]\n",
        "  for i in output:\n",
        "    x,y,width,height = i['box']\n",
        "    left_eyeX,left_eyeY = i['keypoints']['left_eye']\n",
        "    right_eyeX,right_eyeY = i['keypoints']['right_eye']\n",
        "    noseX,noseY = i['keypoints']['nose']\n",
        "    mouth_leftX,mouth_leftY = i['keypoints']['mouth_left']\n",
        "    mouth_rightX,mouth_rightY = i['keypoints']['mouth_right']\n",
        "\n",
        "    cv2.circle(img,center=(left_eyeX,left_eyeY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(right_eyeX,right_eyeY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(noseX,noseY),color=(0,0,0),thickness=0,radius=2)\n",
        "    cv2.circle(img,center=(mouth_leftX,mouth_leftY),color=(0,0,0),thickness=0,radius=0)\n",
        "    cv2.circle(img,center=(mouth_rightX,mouth_rightY),color=(0,0,0),thickness=0,radius=0)\n",
        "\n",
        "    cv2.rectangle(img,pt1=(x,y),pt2=(x+width,y+height),color=(0,0,0),thickness=0)\n",
        "  img1 = img[y:y+height, x:x+width]\n",
        "  if len(output) == 0:\n",
        "    img1 = img[150:150+250, 180:180+200]\n",
        "  else:\n",
        "    img1 = img[y:y+height, x:x+width]\n",
        "  cv2.imwrite(img_path, img1)\n",
        "  cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "BAbD88st2eRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model + fine-tuning + predictions**"
      ],
      "metadata": {
        "id": "5UMYNeXn2qyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "BATCH_SIZE=32\n",
        "BEST_MODEL_FILE='best_model.h5'"
      ],
      "metadata": {
        "id": "dmsKmNsg2jht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import mobilenet,mobilenet_v2\n",
        "INPUT_SHAPE=224\n",
        "\n",
        "net_model=mobilenet_v2\n",
        "net_model_class=net_model.MobileNetV2\n",
        "\n",
        "model = net_model_class(weights='imagenet',input_shape=(INPUT_SHAPE,INPUT_SHAPE,3))"
      ],
      "metadata": {
        "id": "GjxnbdYv2tex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def net():\n",
        "    base_model = net_model_class(weights='imagenet',input_shape=(INPUT_SHAPE,INPUT_SHAPE,3),include_top=False, pooling='avg', classes=7)\n",
        "    x=base_model.output\n",
        "    x = Dense(7, activation='softmax', use_bias=True)(x)\n",
        "    model=Model(base_model.inputs, x)\n",
        "    return model,base_model\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\n",
        "        train_dir,\n",
        "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "CJZWik-V2vc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model,base_model=net()\n",
        "for l in base_model.layers:\n",
        "    l.trainable=False\n",
        "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
        "#model.summary()\n",
        "es=EarlyStopping(monitor='val_acc',patience=9)\n",
        "mc = ModelCheckpoint(BEST_MODEL_FILE, monitor='val_acc', verbose=1, save_best_only=True)\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples//BATCH_SIZE,\n",
        "      epochs=45,\n",
        "      callbacks=[es,mc],\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples//BATCH_SIZE)"
      ],
      "metadata": {
        "id": "OAlSmdVS2yNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}